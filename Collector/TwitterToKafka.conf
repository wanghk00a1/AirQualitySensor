# 执行py 读取twitter数据，通过kafka-channel存到kafka中
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# Search and Replace Interceptor, 看情况考虑是否启用，优化数据
#a1.sources.r1.interceptors = i1
#a1.sources.r1.interceptors.i1.type = search_replace
#a1.sources.r1.interceptors.i1.search-replace.searchPattern = (\\\\r|\\\\n)
#a1.sources.r1.interceptors.i1.search-replace.replaceString = [ ]

# Exec Source
a1.sources.r1.type = exec
a1.sources.r1.restart = false
a1.sources.r1.command = /opt/spark-twitter/7305CloudProject/Collector/python/tweetStdout.py
a1.sources.r1.channels = c1


# kafka channel
#a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
#a1.channels.c1.kafka.bootstrap.servers = gpu7:9092,gpu7-x1:9092,gpu7-x2:9092,student19-x1:9092,student19-x2:9092,student20-x1:9092,student20-x2:9092,student21-x1:9092,student21-x2:9092
#a1.channels.c1.kafka.topic = alex1
#a1.channels.c1.kafka.consumer.group.id = flume-consumer
#Flume的headers中的信息混合着内容一起写入kafka的消息中，无论headers是否为空时都出现了奇怪的特殊字符
#a1.channels.c1.kafka.parseAsFlumeEvent=false


# Twitter Source 试验性的twitter flume 接口
#a1.sources.r1.type = org.apache.flume.source.twitter.TwitterSource
#a1.sources.r1.consumerKey = pH8zAmloqT0xBwit303LI0zPd
#a1.sources.r1.consumerSecret = h1NfmL8t3Ry60eranoz61PYWXNir9539QyzQ0i4L2jqaU0IQDC
#a1.sources.r1.accessToken = 4244469072-FxT513aKjBWrSZipMYzhMdlN6AYha77d90MV3Hh
#a1.sources.r1.accessTokenSecret = ks69jGoDCEVeKarwBqztsoWt0xdPIamllVKq9MgGu3NMi
#a1.sources.r1.maxBatchSize = 1000
#a1.sources.r1.maxBatchDurationMillis = 1000
#a1.sources.r1.channels = c1
#a1.sources.r1.lang = en
#a1.sources.r1.keywords = football,Oscar

# Channel
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
#The maximum number of events stored in the channel
a1.channels.c1.capacity = 10000
#The maximum number of events the channel will take from a source or give to a sink per transaction
a1.channels.c1.transactionCapacity = 10000

#写到kafka
a1.sinks.k1.channel = c1
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic = alex1
a1.sinks.k1.kafka.bootstrap.servers = gpu7:9092,gpu7-x1:9092,gpu7-x2:9092,student19-x1:9092,student19-x2:9092
a1.sinks.k1.kafka.flumeBatchSize = 1000
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.linger.ms = 1
a1.sinks.k1.kafka.producer.compression.type = snappy


