# 用于直接调Twitter API, 改为读Kafka 后, 此处可删除
ACCESS_TOKEN_KEY = "122528040-BKddrSVzrcmyRBKPVHBdL65mgNanVtnxJacmrOFP"
ACCESS_TOKEN_SECRET = "tu6nFiQHtlSSdJqRJE9ua4hgJ7oGBFIT8nD3zh1Gdp1Jt"
CONSUMER_KEY = "RbABZ6hZYconrA9M3rIeh8W3N"
CONSUMER_SECRET = "Vw56Lafdn7SiWwDk6M0l7e2ZmBVcYm1f4GLk6uyL5bTsWmwiY1"


# Spark 默认是从hdfs读取文件,
# 可以指定sc.textFile(path),hdfs://表示从hdfs文件系统上读;file:// 表示从本地文件系统读;
# Absolute path of the Sentiment140 Training data.
# This contains 1.6 million tweets with polarity and other useful info.
# This will be used for creating a Naive Bayes Model.
//SENTIMENT140_TRAIN_DATA_ABSOLUTE_PATH = "/data/training.1600000.processed.noemoticon.csv"
SENTIMENT140_TRAIN_DATA_ABSOLUTE_PATH = "/weibo/weibo.csv"

# Absolute path of the Sentiment140 Testing data.
//SENTIMENT140_TEST_DATA_ABSOLUTE_PATH = "/data/testdata.manual.2009.06.14.csv"
SENTIMENT140_TEST_DATA_ABSOLUTE_PATH = "/weibo/weibo.csv"

# Absolute path to save the Naive Bayes Model of training data.
NAIVEBAYES_MODEL_ABSOLUTE_PATH = "/tweets_sentiment/NBModel/"

# Absolute path to save the accuracy of Naive Bayes Model after executing it with test data as above ["SENTIMENT140_TEST_DATA_ABSOLUTE_PATH"].
NAIVEBAYES_MODEL_ACCURACY_ABSOLUTE_PATH = "/tweets_sentiment/accuracy/"

# Do we need to save raw tweets to disk?
# If set to true, raw tweets retrieved are compressed and saved to disk in the folder structure based on date and time for each batch.
SAVE_RAW_TWEETS = false

# Absolute path to save raw tweets. Tweets will compressed and in multiple folders created by dates based on batch time.
TWEETS_RAW_ABSOLUTE_PATH = "/tweets_sentiment/raw_tweets/"

# Absolute path to save classified tweets. Tweets will compressed and in multiple folders created by dates based on batch time.
TWEETS_CLASSIFIED_ABSOLUTE_PATH = "/tweets_sentiment/classified_tweets/"

# Name of the file in the classpath [resources folder] which contains the stop words.
NLTK_STOPWORDS_FILE_NAME = NLTK_English_Stopwords_Corpus.txt

# Spark Streaming job runs in batches. Each batch is for the following duration.
# Tweak it based on your requirement.
STREAMING_MICRO_BATCH_TIME_IN_SECONDS = 15

# This will be total run time of Spark Streaming job.
# Spark Streaming job will run for these minutes and retreives, processes tweets and predicts and visualizes sentiment in real-time.
# Tweak it based on your requirement.
TOTAL_RUN_TIME_IN_MINUTES = -1


# 读 Kafka 配置
BOOTSTRAP_SERVER = "gpu5:9092"
GROUP_ID = "spark-consumer"
AUTO_OFFSET_RESET = "latest"
KAFKA_TOPICS = "test04"

# 吐入到Kafka
#gpu7:9092,gpu7-x1:9092,gpu7-x2:9092,student19-x1:9092,student19-x2:9092,student20-x1:9092,student20-x2:9092,student21-x1:9092,student21-x2:9092
BOOTSTRAP_SERVER_PRODUCER = "gpu5:9092,gpu5-x1:9092,gpu5-x2:9092"
GROUP_ID_PRODUCER = "spark-producer"
KAFKA_TOPICS_PRODUCER = "twitter-result1"

#结果写到数据库
MYSQL_ADDRESS = "jdbc:mysql://localhost:3306/weibo"
MYSQL_USERNAME = "hduser"
MYSQL_PASSWORD = "student"
MYSQL_DATABASE = "weibo_attitude"

