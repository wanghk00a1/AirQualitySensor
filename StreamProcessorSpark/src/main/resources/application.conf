# Spark 默认是从hdfs读取文件,
# 可以指定sc.textFile(path),hdfs://表示从hdfs文件系统上读;file:// 表示从本地文件系统读;
# Absolute path of the Sentiment140 Training data.
# This contains 1.6 million tweets with polarity and other useful info.
# This will be used for creating a Naive Bayes Model.
//SENTIMENT140_TRAIN_DATA_ABSOLUTE_PATH = "/data/training.1600000.processed.noemoticon.csv"
SENTIMENT140_TRAIN_DATA_ABSOLUTE_PATH = "/weibo/weibo.csv"

# Absolute path of the Sentiment140 Testing data.
//SENTIMENT140_TEST_DATA_ABSOLUTE_PATH = "/data/testdata.manual.2009.06.14.csv"
SENTIMENT140_TEST_DATA_ABSOLUTE_PATH = "/weibo/weibo.csv"

# Name of the file in the classpath [resources folder] which contains the stop words.
NLTK_STOPWORDS_FILE_NAME = NLTK_English_Stopwords_Corpus.txt

# Absolute path to save the Naive Bayes Model of training data.
NAIVEBAYES_MODEL_ABSOLUTE_PATH = "/tweets_sentiment/NBModel/"

# Absolute path to save the accuracy of Naive Bayes Model after executing it with test data as above ["SENTIMENT140_TEST_DATA_ABSOLUTE_PATH"].
NAIVEBAYES_MODEL_ACCURACY_ABSOLUTE_PATH = "/tweets_sentiment/accuracy/"


# Spark Streaming job runs in batches. Each batch is for the following duration.
STREAMING_MICRO_BATCH_TIME_IN_SECONDS = 15

# This will be total run time of Spark Streaming job.
TOTAL_RUN_TIME_IN_MINUTES = -1


# Kafka consumer 配置
BOOTSTRAP_SERVER = "student13:9092"
GROUP_ID = "spark-consumer"
AUTO_OFFSET_RESET = "latest"
KAFKA_TOPICS = "weibo"

# Kafka producer 配置
BOOTSTRAP_SERVER_PRODUCER = "student13:9092,student13-x1:9092"
GROUP_ID_PRODUCER = "spark-producer"
KAFKA_TOPICS_PRODUCER = "twitter-result1"

#结果写到数据库
MYSQL_ADDRESS = "jdbc:mysql://localhost:3306/weibo"
MYSQL_USERNAME = "hduser"
MYSQL_PASSWORD = "student"
MYSQL_DATABASE = "weibo_attitude"

